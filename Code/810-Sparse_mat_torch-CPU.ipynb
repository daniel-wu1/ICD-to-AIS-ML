{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: ICD-AIS conversion using Deep Learning\n",
    "\n",
    "### This script creates sparse matrices for the input and output files and creates a neural net using that data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "\n",
    "import modules.helper_functions_800 as hlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_train_file = \"../Data/train_ais_agecat_I9_A05.csv\"\n",
    "icd_train_file =\"../Data/train_icd_agecat_I9_A05.csv\"\n",
    "ais_val_file = \"../Data/val_ais_agecat_I9_A05.csv\"\n",
    "icd_val_file =\"../Data/val_icd_agecat_I9_A05.csv\"\n",
    "ais_test_file = \"../Data/test_ais_agecat_I9_A05.csv\"\n",
    "icd_test_file =\"../Data/test_icd_agecat_I9_A05.csv\"\n",
    "ais_codes_file = \"../Data/AIS08_codes.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the below line means you MUST [create sparse matrices](#create_sparse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on a batch size for training neural net\n",
    "# This is up here to create an array of spliced sparse matrices based on batch size\n",
    "batch_size = 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_train = pd.read_csv(icd_train_file, header=None, names=[\"icd_code\"])\n",
    "icd_val = pd.read_csv(icd_val_file, header=None, names=[\"icd_code\"])\n",
    "icd_test = pd.read_csv(icd_test_file, header=None, names=[\"icd_code\"])\n",
    "ais_train = pd.read_csv(ais_train_file, header=None, names=[\"icd_code\"])\n",
    "ais_val = pd.read_csv(ais_val_file, header=None, names=[\"icd_code\"])\n",
    "ais_test = pd.read_csv(ais_test_file, header=None, names=[\"icd_code\"])\n",
    "\n",
    "# load AIS codes\n",
    "ais_map = pd.read_csv(ais_codes_file, header=0, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve all data to train the neural net\n",
    "\n",
    "### Only use this if you want to skip to [creating a neural net](#neural_net) with a new kernel as opposed to running the whole notebook again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r icd_codes\n",
    "icd_dict = dict(zip(icd_codes, list(range(len(icd_codes)))))\n",
    "\n",
    "%store -r ais_codes\n",
    "ais_dict = dict(zip(ais_codes, list(range(len(ais_codes)))))\n",
    "\n",
    "%store -r sparse_icd_train\n",
    "%store -r sparse_icd_test\n",
    "%store -r sparse_icd_val\n",
    "\n",
    "%store -r sparse_ais_train\n",
    "%store -r sparse_ais_test\n",
    "%store -r sparse_ais_val\n",
    "\n",
    "%store -r spliced_icd_train\n",
    "%store -r spliced_icd_test\n",
    "%store -r spliced_icd_val\n",
    "\n",
    "%store -r spliced_ais_train\n",
    "%store -r spliced_ais_test\n",
    "%store -r spliced_ais_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all unique patient ICD and AIS codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/sfs/qumulo/qhome/qdy4zt/ICD_to_AIS_playground/Code/modules/helper_functions_800.py\u001b[0m in \u001b[0;36mget_unique_codes\u001b[0;34m(dfs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m              \u001b[0;31m# extract line and split into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m# loop through terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/9.2.0/jupyter_conda/2020.11-py3.8/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m                 )\n\u001b[1;32m   2000\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/9.2.0/jupyter_conda/2020.11-py3.8/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, pat, n, expand)\u001b[0m\n\u001b[1;32m   2687\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mforbid_nonstring_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bytes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2689\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/9.2.0/jupyter_conda/2020.11-py3.8/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_split\u001b[0;34m(arr, pat, n)\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/9.2.0/jupyter_conda/2020.11-py3.8/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[0;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mna_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/9.2.0/jupyter_conda/2020.11-py3.8/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_map_object\u001b[0;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/9.2.0/jupyter_conda/2020.11-py3.8/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get unique icd codes from all sets\n",
    "icd_codes = hlp.get_unique_codes([icd_train, icd_val, icd_test])\n",
    "%store icd_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of ICD codes\n",
    "icd_dict = dict(zip(icd_codes, list(range(len(icd_codes)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/sfs/qumulo/qhome/qdy4zt/ICD_to_AIS_playground/Code/modules/helper_functions_800.py\u001b[0m in \u001b[0;36mget_unique_codes\u001b[0;34m(dfs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m              \u001b[0;31m# extract line and split into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m# loop through terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get unique ais codes from all sets\n",
    "ais_codes = hlp.get_unique_codes([ais_train, ais_val, ais_test])\n",
    "%store ais_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of AIS codes\n",
    "ais_dict = dict(zip(ais_codes, list(range(len(ais_codes)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create_sparse'></a>\n",
    "## Create sparse matrices\n",
    "\n",
    "Run the three below lines when changing batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size is the NUMBER OF PATIENTS we are analyzing at once\n",
    "def get_list_of_spliced_matrices(row, col, data, pt_num, dic):\n",
    "    # Start at row 0\n",
    "    current_row = 0\n",
    "    end = 0\n",
    "    #print(\"Length of rows \" + str(len(row)))\n",
    "    #print(\"Total pt number \" + str(pt_num))\n",
    "    #print(\"Batch size \" + str(batch_size))\n",
    "    # If pt_num is < batch size then 1 is the num_sparse_matrices, otherwise divy up into batches (sparse matrices)\n",
    "    if batch_size < pt_num:\n",
    "        # So if batch size >= pt_num then divide pt_num by batch size, that's the number of sparse matrices\n",
    "        num_sparse_matrices = int(math.ceil(pt_num/(batch_size)))\n",
    "    else:\n",
    "        num_sparse_matrices = 1\n",
    "        \n",
    "    # Now go thru the determined number of sparse matrices and add batches of matrices\n",
    "    sparse_batch_list = []\n",
    "    for i in range(0, num_sparse_matrices):\n",
    "        #print(row[current_row])\n",
    "        #print(\"Current row \" + str(current_row))\n",
    "        current_pt = row[current_row]\n",
    "        # If we add batch_size to current row and we are below pt_num then good, lets keep going\n",
    "        #print(\"On matrix \" + str(i+1) + \"/\" + str(num_sparse_matrices), end=\"\\r\")\n",
    "        # Now lets add a smaller sparse coo tensor to the batch list\n",
    "        rows = []\n",
    "        cols = []\n",
    "        datas = []\n",
    "        last_pt = 0\n",
    "        if (current_pt + batch_size) < pt_num:\n",
    "            end = row.index((current_pt + batch_size))\n",
    "            #print(\"We aren't at end...\")\n",
    "            #print(\"Current Patient \" + str(current_pt))\n",
    "            #print(\"End \" + str(end))\n",
    "            \n",
    "        # Else end is pt_num\n",
    "        else:\n",
    "            end = row.index(pt_num-1)+1\n",
    "            #print(\"Current Patient \" + str(current_pt))\n",
    "            #print(\"End \" + str(end))\n",
    "            \n",
    "        \n",
    "        while current_row < end:\n",
    "            subtractor = ((batch_size*i))\n",
    "            #print(\"SUBTRACTOR \" + str(subtractor))\n",
    "            rows.append((row[current_row] - subtractor))\n",
    "            last_pt = (row[current_row] - subtractor)\n",
    "            cols.append(col[current_row])\n",
    "            datas.append(data[current_row])\n",
    "            current_row += 1\n",
    "            \n",
    "        missing_codes = list(map(int, hlp.find_missing(cols, dic)))\n",
    "        cols.extend(missing_codes)\n",
    "        #print(\"Missing codes length: \" + str(len(missing_codes)))\n",
    "        for i in range(len(missing_codes)):\n",
    "            rows.append(last_pt)\n",
    "            datas.append(0)\n",
    "            \n",
    "        #print(\"ROWS LENGTH \" + str(len(rows)))\n",
    "        tmp_tensor = torch.sparse_coo_tensor([rows,cols], \n",
    "                                datas, \n",
    "                                dtype=torch.float)\n",
    "        \n",
    "        l = 1\n",
    "        if len(rows) != batch_size:\n",
    "            rows.append(last_pt + l)\n",
    "            cols.append(0)\n",
    "            datas.append(0)\n",
    "        sparse_batch_list.append(tmp_tensor.detach().clone())\n",
    "        del rows\n",
    "        del cols\n",
    "        del datas\n",
    "        del tmp_tensor\n",
    "            \n",
    "    return sparse_batch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training, testing, and validation ICD matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training matrices...\n",
      "Missing codes length: 155\n",
      "Number patients 895455\n",
      "Length of all sparse matrices together: 895455\n",
      "\n",
      "Creating testing matrices...\n",
      "Missing codes length: 3483\n",
      "Number patients 99717\n",
      "Length of all sparse matrices together: 99717\n",
      "\n",
      "Creating validation matrices...\n",
      "Missing codes length: 7776\n",
      "Number patients 2000\n",
      "Length of all sparse matrices together: 1000\n",
      "Stored 'sparse_icd_train' (Tensor)\n",
      "Stored 'sparse_icd_test' (Tensor)\n",
      "Stored 'sparse_icd_val' (Tensor)\n",
      "Stored 'spliced_icd_train' (list)\n",
      "Stored 'spliced_icd_test' (list)\n",
      "Stored 'spliced_icd_val' (list)\n",
      "CPU times: user 8min 32s, sys: 23.6 s, total: 8min 56s\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Creating training matrices...')\n",
    "row, col, data = hlp.decode_df_coo(icd_train, icd_dict)\n",
    "print(\"Number patients \" + str(len(icd_train)))\n",
    "#sparse_icd_train = torch.sparse_coo_tensor([row,col], data, dtype=torch.float)\n",
    "spliced_icd_train = get_list_of_spliced_matrices(row, col, data, len(icd_train), icd_dict)\n",
    "length = 0\n",
    "for mat in spliced_icd_train:\n",
    "    length += len(mat)\n",
    "print(\"Length of all sparse matrices together: \" + str(length))\n",
    "\n",
    "print('\\nCreating testing matrices...')\n",
    "row, col, data = hlp.decode_df_coo(icd_test, icd_dict)\n",
    "print(\"Number patients \" + str(len(icd_test)))\n",
    "#sparse_icd_test = torch.sparse_coo_tensor([row,col], data, dtype=torch.float)\n",
    "spliced_icd_test = get_list_of_spliced_matrices(row, col, data, len(icd_test), icd_dict)\n",
    "length = 0\n",
    "for mat in spliced_icd_test:\n",
    "    length += len(mat)\n",
    "print(\"Length of all sparse matrices together: \" + str(length))\n",
    "\n",
    "print('\\nCreating validation matrices...')\n",
    "row, col, data = hlp.decode_df_coo(icd_val, icd_dict)\n",
    "print(\"Number patients \" + str(len(icd_val)))\n",
    "#sparse_icd_val = torch.sparse_coo_tensor([row,col], data, dtype=torch.float)\n",
    "spliced_icd_val = get_list_of_spliced_matrices(row, col, data, len(icd_val), icd_dict)\n",
    "print(\"Length of all sparse matrices together: \" +  str(len(spliced_icd_val[0])))\n",
    "\n",
    "\n",
    "\n",
    "%store sparse_icd_train\n",
    "%store sparse_icd_test\n",
    "%store sparse_icd_val\n",
    "%store spliced_icd_train\n",
    "%store spliced_icd_test\n",
    "%store spliced_icd_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training, testing, and validation AIS matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing codes length: 0\n",
      "Creating training matrices...\n",
      "Number patients 895455\n",
      "Length of all sparse matrices together: 895455\n",
      "\n",
      "Creating testing matrices...\n",
      "Missing codes length: 111\n",
      "Number patients 99717\n",
      "Length of all sparse matrices together: 99717\n",
      "\n",
      "Creating validation matrices...\n",
      "Missing codes length: 1118\n",
      "Number patients 2000\n",
      "Length of all sparse matrices together: 1000\n",
      "Stored 'sparse_ais_train' (Tensor)\n",
      "Stored 'sparse_ais_test' (Tensor)\n",
      "Stored 'sparse_ais_val' (Tensor)\n",
      "Stored 'spliced_ais_train' (list)\n",
      "Stored 'spliced_ais_test' (list)\n",
      "Stored 'spliced_ais_val' (list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "row, col, data = hlp.decode_df_coo(ais_train, ais_dict)\n",
    "print('Creating training matrices...')\n",
    "#sparse_ais_train = torch.sparse_coo_tensor([row,col], data, dtype=torch.float)\n",
    "print(\"Number patients \" + str(len(ais_train)))\n",
    "spliced_ais_train = get_list_of_spliced_matrices(row, col, data, len(ais_train), ais_dict)\n",
    "length = 0\n",
    "for mat in spliced_ais_train:\n",
    "    length += len(mat)\n",
    "print(\"Length of all sparse matrices together: \" + str(length))\n",
    "\n",
    "print(\"\\nCreating testing matrices...\")\n",
    "row, col, data = hlp.decode_df_coo(ais_test, ais_dict)\n",
    "#sparse_ais_test = torch.sparse_coo_tensor([row,col], data, dtype=torch.float)\n",
    "print(\"Number patients \" + str(len(ais_test)))\n",
    "spliced_ais_test = get_list_of_spliced_matrices(row, col, data, len(ais_test), ais_dict)\n",
    "length = 0\n",
    "for mat in spliced_ais_test:\n",
    "    length += len(mat)\n",
    "print(\"Length of all sparse matrices together: \" + str(length))\n",
    "\n",
    "print(\"\\nCreating validation matrices...\")\n",
    "row, col, data = hlp.decode_df_coo(ais_val, ais_dict)\n",
    "print(\"Number patients \" + str(len(ais_val)))\n",
    "#sparse_ais_val = torch.sparse_coo_tensor([row,col], data, dtype=torch.float)\n",
    "spliced_ais_val = get_list_of_spliced_matrices(row, col, data, len(ais_val), ais_dict)\n",
    "print(\"Length of all sparse matrices together: \" +  str(len(spliced_ais_val[0])))\n",
    "\n",
    "\n",
    "%store sparse_ais_train\n",
    "%store sparse_ais_test\n",
    "%store sparse_ais_val\n",
    "%store spliced_ais_train\n",
    "%store spliced_ais_test\n",
    "%store spliced_ais_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test validity of create sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 600 µs, sys: 0 ns, total: 600 µs\n",
      "Wall time: 605 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create inverted dicts to test validity\n",
    "icd_inverted_dict = {v: k for k, v in icd_dict.items()}\n",
    "ais_inverted_dict = {v: k for k, v in ais_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ne, matrix_df = hlp.test_sparse_matrix(sparse_icd_train, icd_train, icd_inverted_dict)\n",
    "hlp.print_diff(ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes are identical\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ne, matrix_df = hlp.test_sparse_matrices(spliced_icd_test, icd_test, icd_inverted_dict)\n",
    "hlp.print_diff(ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes are identical\n",
      "CPU times: user 293 ms, sys: 0 ns, total: 293 ms\n",
      "Wall time: 291 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ne, matrix_df = hlp.test_sparse_matrices(spliced_icd_val, icd_val, icd_inverted_dict)\n",
    "hlp.print_diff(ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/sfs/qumulo/qhome/qdy4zt/ICD_to_AIS_playground/Code/modules/helper_functions_800.py\u001b[0m in \u001b[0;36mtest_sparse_matrices\u001b[0;34m(sparse_matrices, orig_df, dict_)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mnum_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mcode_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcode_string\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ne, matrix_df = hlp.test_sparse_matrices(spliced_ais_train, ais_train, ais_inverted_dict)\n",
    "hlp.print_diff(ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes are identical\n",
      "CPU times: user 11.5 s, sys: 0 ns, total: 11.5 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ne, matrix_df = hlp.test_sparse_matrices(spliced_ais_test, ais_test, ais_inverted_dict)\n",
    "hlp.print_diff(ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes are identical\n",
      "CPU times: user 177 ms, sys: 0 ns, total: 177 ms\n",
      "Wall time: 176 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ne, matrix_df = hlp.test_sparse_matrices(spliced_ais_val, ais_val, ais_inverted_dict)\n",
    "hlp.print_diff(ne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='neural_net'></a>\n",
    "## Set up neural net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9178\n",
      "1983\n"
     ]
    }
   ],
   "source": [
    "# Set parameters...\n",
    "# For training\n",
    "learning_rate = 0.0015\n",
    "num_epochs = 10\n",
    "# For neural net\n",
    "input_size = len(icd_dict)\n",
    "num_classes = len(ais_dict)\n",
    "print(input_size)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Try to run on GPU else run on CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a neural net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__() # Init the superclass nn.Module\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin1 = nn.Linear(input_size, int(input_size/4))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(int(input_size/4), num_classes)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, int(input_size/4)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(input_size/4), num_classes),\n",
    "            nn.ReLU(),\n",
    "            # find a function to keep between 0-1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = self.linear_relu_stack(x)\n",
    "        q = nn.functional.softmax(r, dim=0)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in range(0, len(spliced_icd_train)):\n",
    "#    print(spliced_icd_train[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset and a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMatrixDataset(Dataset):\n",
    "    def __init__(self, spliced_icd, spliced_ais):\n",
    "        self.icd_spliced = spliced_icd\n",
    "        self.ais_spliced = spliced_ais\n",
    "        #print(len(self.icd_spliced))\n",
    "        #print(len(self.ais_spliced))\n",
    "        self.count = 0\n",
    "        self.length = len(self.icd_spliced)\n",
    "        if self.length > 1:\n",
    "            self.length = self.length - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):  \n",
    "        # Get indices for icd and ais and return\n",
    "        self.count += 1\n",
    "        print((str(self.count) + \" / \" + str(self.length)), end=\"\\r\")\n",
    "        return self.icd_spliced[self.count-1], self.ais_spliced[self.count-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader using dataset\n",
    "train_loader = DataLoader(dataset=SparseMatrixDataset(spliced_icd_train, spliced_ais_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=SparseMatrixDataset(spliced_icd_val, spliced_ais_val), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=SparseMatrixDataset(spliced_icd_test, spliced_ais_test), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a neural net and training it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model and set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init network\n",
    "model = NeuralNetwork(input_size=input_size, num_classes=num_classes).to(device) # You can store\n",
    "\n",
    "# Set loss and optimizer\n",
    "loss_function = nn.BCELoss() #nn.MSELoss() Binary cross entropy seems to be the best\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch #1...\n",
      "Training data...\n",
      "On batch 0 / 895\n",
      "On batch 1 / 895\n",
      "On batch 2 / 895\n",
      "On batch 3 / 895\n",
      "On batch 4 / 895\n",
      "On batch 5 / 895\n",
      "On batch 6 / 895\n",
      "On batch 7 / 895\n",
      "On batch 8 / 895\n",
      "On batch 9 / 895\n",
      "On batch 10 / 895\n",
      "On batch 11 / 895\n",
      "On batch 12 / 895\n",
      "On batch 13 / 895\n",
      "On batch 14 / 895\n",
      "On batch 15 / 895\n",
      "On batch 16 / 895\n",
      "On batch 17 / 895\n",
      "On batch 18 / 895\n",
      "On batch 19 / 895\n",
      "On batch 20 / 895\n",
      "On batch 21 / 895\n",
      "On batch 22 / 895\n",
      "On batch 23 / 895\n",
      "On batch 24 / 895\n",
      "On batch 25 / 895\n",
      "On batch 26 / 895\n",
      "On batch 27 / 895\n",
      "On batch 28 / 895\n",
      "On batch 29 / 895\n",
      "On batch 30 / 895\n",
      "On batch 31 / 895\n",
      "On batch 32 / 895\n",
      "On batch 33 / 895\n",
      "On batch 34 / 895\n",
      "On batch 35 / 895\n",
      "On batch 36 / 895\n",
      "On batch 37 / 895\n",
      "On batch 38 / 895\n",
      "On batch 39 / 895\n",
      "On batch 40 / 895\n",
      "On batch 41 / 895\n",
      "On batch 42 / 895\n",
      "On batch 43 / 895\n",
      "On batch 44 / 895\n",
      "On batch 45 / 895\n",
      "On batch 46 / 895\n",
      "On batch 47 / 895\n",
      "On batch 48 / 895\n",
      "On batch 49 / 895\n",
      "On batch 50 / 895\n",
      "On batch 51 / 895\n",
      "On batch 52 / 895\n",
      "On batch 53 / 895\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f5efb16fc2de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#start = time.process_time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m# gradient descent or adam step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_test_split, stratify by ais codes???\n",
    "# Flag to let us know if this is the first save of the model\n",
    "first_save = True\n",
    "# Train network\n",
    "val_losses = [] # List of losses from each of the past epochs\n",
    "for epoch in range(num_epochs):\n",
    "    print('Starting epoch #' + str(epoch+1) + '...')\n",
    "    print('Training data...')\n",
    "    for batch_index, (icds, aiss) in enumerate((train_loader)):\n",
    "        #print(icds.shape)\n",
    "        for idx in range(0, len(icds)):\n",
    "            #print(\"On batch \" + str(idx) + \" / \" + str(len(icds)), end=\"\\r\")\n",
    "            icd_batch = icds[idx].to_dense()\n",
    "            ais_batch = aiss[idx].to_dense()\n",
    "            # forward\n",
    "            #start = time.process_time()\n",
    "            #print('Getting scores', flush=True)\n",
    "            scores = model(icd_batch)\n",
    "            #print(\"Time to get scores: \" + str(time.process_time() - start))\n",
    "            #start = time.process_time()\n",
    "            loss = loss_function(scores, ais_batch)\n",
    "            #print(\"Time to get loss: \" + str(time.process_time() - start))\n",
    "            del icd_batch\n",
    "            del ais_batch\n",
    "            del scores\n",
    "            # backward\n",
    "            #start = time.process_time()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # gradient descent or adam step\n",
    "            optimizer.step()\n",
    "            #print(\"Time for backwards propagation: \" + str(time.process_time() - start))\n",
    "            print(\"On batch \" + str(idx) + \" / \" + str(len(icds)))\n",
    "    print('Loss at epoch number ' + str(epoch+1) + ' is ' + str(float(loss)))\n",
    "     \n",
    "    print('Validating data...')\n",
    "    new_val_losses = [] # List of losses for this epoch      \n",
    "    # Validation data don't train, just see where u are after each epoch # When validating round up/down\n",
    "    for batch_index, (icd_batch, ais_batch) in enumerate((val_loader)):\n",
    "        # forward\n",
    "        scores = model(icd_batch)\n",
    "        loss = loss_function(scores, ais_batch)\n",
    "        new_val_losses.append(loss.item())\n",
    "        del icd_batch\n",
    "        del ais_batch\n",
    "        del scores\n",
    "        del loss\n",
    "    \n",
    "    # Check if we are getting a less accurate model\n",
    "    if len(val_losses) > 0:\n",
    "        if hlp.get_list_avg(new_val_losses) > hlp.get_list_avg(val_losses):\n",
    "            print(\"Model is worsening... early stopping\")\n",
    "            model = torch.load(PATH)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Model continuing to improve... saving state\")\n",
    "            # Then save the model\n",
    "            if first_save:\n",
    "                # Store trained model for the first time\n",
    "                # https://stackoverflow.com/a/43819235/16393363\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                # Load for the first time\n",
    "                model = NeuralNetwork(input_size=input_size, num_classes=num_classes)\n",
    "                model.load_state_dict(torch.load(PATH))\n",
    "            else: \n",
    "                # Save entire model\n",
    "                torch.save(model, PATH)\n",
    "                model = torch.load(PATH)\n",
    "            val_losses.append(new_val_losses)\n",
    "    else:\n",
    "        val_losses.append(new_val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-900b4051f978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load model and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0micd_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mais_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PATH' is not defined"
     ]
    }
   ],
   "source": [
    "# Load model and test\n",
    "model = torch.load(PATH)\n",
    "print('Testing data...')\n",
    "for batch_index, (icd_batch, ais_batch) in enumerate((test_loader)):\n",
    "    # forward\n",
    "    scores = model(icd_batch.)\n",
    "    scores = (scores>0.5).float() # Set scores over 0.5 to 1 else 0\n",
    "    # Create a dataframe from the information that we have!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store and load model for the first time\n",
    "\n",
    "#### Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to store model at\n",
    "PATH = '/home/qdy4zt/ICD_to_AIS_playground/Models/one-batch-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store trained model for the first time\n",
    "# https://stackoverflow.com/a/43819235/16393363\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load for the first time\n",
    "model = NeuralNetwork(input_size=input_size, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store and load model after first store/load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entire model\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'losses' (list)\n"
     ]
    }
   ],
   "source": [
    "%store losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('batch')\n",
    "plt.title(\"Learning rate %f\"%(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper__addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0bd0fdbdaef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy on training set: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_icd_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_ais_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy on test set: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_icd_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_ais_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-0bd0fdbdaef7>\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[0;34m(sparse_icd, sparse_ais, model)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurrent_row\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_icd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdivisor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_dense_submat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_icd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5f82b8705743>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_relu_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper__addmm)"
     ]
    }
   ],
   "source": [
    "divisor = 900 # Set to 1 to run for all data\n",
    "\n",
    "# Function that gets submatrix in dense format\n",
    "def get_dense_submat(full_sparse_mat, start, end, ais=False):\n",
    "    try:\n",
    "        if ais == False:\n",
    "            return torch.index_select(full_sparse_mat,0,torch.tensor(list(range(start, end)))).to_dense()\n",
    "        else:\n",
    "            raise(\"Not sure what's going on\")\n",
    "    except:\n",
    "        return torch.index_select(full_sparse_mat,0,torch.tensor(list(range(start, end))))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Okay all of this is junk im going to start over\n",
    "# What I think I need:\n",
    "#   - Get predictions for each patient\n",
    "#   - Get the ais codes for each patient\n",
    "#   - Compare those, then incr  \n",
    "    \n",
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(sparse_icd, sparse_ais, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    # Keep track of where we are\n",
    "    current_row = 0\n",
    "    end = 1983\n",
    "    # Transfer to GPU\n",
    "    sparse_icd, sparse_ais = sparse_icd.to(device), sparse_ais.to(device)\n",
    "    with torch.no_grad():\n",
    "        # While current row isn't higher than the desired length\n",
    "        while not current_row >= (len(sparse_icd) / (divisor * batch_size)):\n",
    "            # Get predictions\n",
    "            scores = model(get_dense_submat(sparse_icd, current_row, end))\n",
    "            _, predictions = scores.max(1)\n",
    "            predictions = predictions.to(device)\n",
    "\n",
    "            \n",
    "            dense_pred = get_dense_submat(predictions, current_row, end)\n",
    "            dense_ais = get_dense_submat(sparse_ais, current_row, end, ais=True)\n",
    "            # For row in batch\n",
    "            for row in range(current_row, end):\n",
    "                print(dense_pred)\n",
    "                print(dense_ais)\n",
    "                # If prediction matches sparse ais, add another correct\n",
    "                num_correct += (dense_pred[row] == \n",
    "                                dense_ais[row])\n",
    "                num_samples += predictions.size(0)\n",
    "                return 'done'\n",
    "            current_row = end\n",
    "            # If end is greater than the length we are trying to go to, just set end to that length\n",
    "            if end >= (len(sparse_icd) / (divisor * batch_size)):\n",
    "                end = (len(sparse_icd) / (divisor * batch_size))\n",
    "            end += 1983\n",
    "\n",
    "    model.train()\n",
    "    return num_correct/num_samples\n",
    "\n",
    "print(f\"Accuracy on training set: \")\n",
    "print(check_accuracy(sparse_icd_train, sparse_ais_train, model)*100)\n",
    "print(f\"Accuracy on test set: \")\n",
    "print(check_accuracy(sparse_icd_test, sparse_ais_test, model)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
